Unit 4: Recent Advancements
===========================

In this unit, we introduce a series of recent topics and trends in ML revolving around the Transformer
deep learning architecture and the concept of *attention*. 
We'll explore current start-of-the-art Large Language Models (LLMs) and  
introduce some open source projects and APIs for working directly with pre-trained LLMs. 
We will discuss the important topic of *benchmarks* and how to use them to evaluate models. 
Finally, we will discuss fine-tuning foundational models to achieve better performance on specific 
tasks and benchmarks by working with some specific examples. 


.. toctree::
   :maxdepth: 1

   intro_to_transformers
   .. hands_on_transformers
   ml_benchmarks
   fine_tuning_transformers



